{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinelliluca/gender_coded_sound_ismir2023/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fD6kv8bhJsyP"
      },
      "source": [
        "### GENDER-CODED SOUND: Analysing the Gendering of Music in Toy Commercials via Multi-Task Learning\n",
        "\n",
        "Demo from https://github.com/marinelliluca/gender_coded_sound_ismir2023\n",
        "\n",
        "#### Usage:\n",
        "- from the menu, select Runtime > Run all\n",
        "- you can change the input video by providing a youtube link to a toy commercial below\n",
        "\n",
        "#### Disclaimer\n",
        "The loaded model supports only two target audiences (masculine or feminine), and is therefore not generalizable to mixed audience commercials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKQIINen-GX2"
      },
      "outputs": [],
      "source": [
        "!pip install yt-dlp\n",
        "!pip install pytorch_lightning\n",
        "!pip install librosa\n",
        "!pip install torchopenl3\n",
        "!pip install ffmpeg moviepy\n",
        "!git clone https://github.com/marinelliluca/gender_coded_sound_ismir2023.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA0tx_x3_3RM",
        "outputId": "79ea5bf2-cfc6-49cf-9c14-cce8af5c8573"
      },
      "outputs": [],
      "source": [
        "%cd gender_coded_sound_ismir2023/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6uAHytC7g-x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from utils import DynamicMultitasker, embedding_dimensions\n",
        "from compute_embeddings import compute_openl3\n",
        "\n",
        "import yt_dlp\n",
        "import moviepy.editor as mp\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import yaml, json\n",
        "from IPython.display import YouTubeVideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwiMNC7ZMMD_"
      },
      "outputs": [],
      "source": [
        "which = \"openl3_env\"\n",
        "voice = True\n",
        "targets_list = [\"Girls/women\", \"Boys/men\"]\n",
        "\n",
        "with open(\"config_save.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# load quantile normalization parameters\n",
        "with open(f\"quantiles_{which}_voice_{voice}_{len(targets_list)}_cls.json\", \"r\") as f:\n",
        "    quantiles = json.load(f)\n",
        "\n",
        "\n",
        "# scales quantization\n",
        "def value_to_level(value, quantiles):\n",
        "    # quantiles = [0.33, 0.67]\n",
        "    if value <= quantiles[0]:\n",
        "        return \"low\"\n",
        "    elif value <= quantiles[1]:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"high\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQf5S_pP6iWQ",
        "outputId": "4598a1a9-84c2-438e-da69-fb41484d4082"
      },
      "outputs": [],
      "source": [
        "#@title Download YouTube video (insert URL)\n",
        "youtube_url = \"https://www.youtube.com/watch?v=iW7yZlEaPA4\" #@param {type:\"string\"}\n",
        "\n",
        "yt_id = youtube_url.split(\"watch?v=\")[-1]\n",
        "\n",
        "video_path = f'./{yt_id}.mp4'\n",
        "\n",
        "ydl_opts = {\n",
        "    'outtmpl': video_path,\n",
        "    \"format\": \"mp4\",\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([youtube_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "evpgvM1o6iWR",
        "outputId": "6b471451-d6dd-4772-9348-c5c7ef3c225c"
      },
      "outputs": [],
      "source": [
        "YouTubeVideo(yt_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2KuGKgKe6iWS"
      },
      "source": [
        "#### Extract audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri-oZOeB6iWS",
        "outputId": "5fec2fa4-b66f-4cba-d61c-eeeaaea4a0b2"
      },
      "outputs": [],
      "source": [
        "video = mp.VideoFileClip(video_path)\n",
        "\n",
        "# trim 5 last seconds (which usually contain the audio logo of the retailer)\n",
        "# video = video.subclip(0, video.duration - 5)\n",
        "\n",
        "video.audio.write_audiofile(video_path.replace(\"mp4\",\"mp3\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5x5u3gN7xDB"
      },
      "source": [
        "### load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moc8wHr77v0Z",
        "outputId": "2bc373d9-303b-4dbd-8294-463a74bc490f"
      },
      "outputs": [],
      "source": [
        "# set the parameters for the model\n",
        "config[\"cls_dict\"][\"target\"] = targets_list # add target list to config\n",
        "params = {\n",
        "    \"input_dim\": embedding_dimensions[\"music\"][which],\n",
        "    \"n_emo\": 6,\n",
        "    \"n_mid\": 12,\n",
        "    \"cls_dict\": config[\"cls_dict\"],\n",
        "    \"filmed\": False,\n",
        "}\n",
        "\n",
        "# Load model:\n",
        "model = DynamicMultitasker(**params)\n",
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "    f\"models/{which}_{voice}_voice_{len(targets_list)}_cls.pt\"\n",
        "    )\n",
        ")\n",
        "model.eval()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b3sRDRLGKsPn"
      },
      "source": [
        "## Compute OpenL3 (env) embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBOpjdTiId3b",
        "outputId": "06ebcf37-6bd1-4439-8267-faf1dce0d910"
      },
      "outputs": [],
      "source": [
        "embedding = compute_openl3(video_path.replace(\"mp4\",\"mp3\")).mean(axis=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8KRGfBwBLWmn"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7HNKlYXLvC3"
      },
      "outputs": [],
      "source": [
        "emotions = ['Happy', 'Beauty', 'Calm', 'Energizing', 'Angry', 'Triumphant']\n",
        "\n",
        "mid_levels = [\n",
        "       'Electric/Acoustic', 'Distorted/Clear', 'Many/Few Instruments',\n",
        "       'Loud/Soft', 'Heavy/Light', 'High/Low pitch', 'Punchy/Smooth',\n",
        "       'Harmonious/Disharmonious', 'Clear melody/No melody',\n",
        "       'Complex/Simple rhythm', 'Dense/Sparse', 'Strong beat/Weak beat'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bk5ydZyKoSv",
        "outputId": "75b70c78-74e2-4e16-f693-c71053ca2156"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    y_mid_pred, y_emo_pred, y_cls_pred = model(\n",
        "        torch.from_numpy(embedding[np.newaxis,:]).float()\n",
        "    )\n",
        "\n",
        "y_emo_pred = y_emo_pred.numpy()\n",
        "y_mid_pred = y_mid_pred.numpy()\n",
        "y_cls_pred = {k: int(torch.argmax(y_cls_pred[k], dim=1).numpy()) for k in config[\"cls_dict\"]}\n",
        "\n",
        "cls_dict = config[\"cls_dict\"]\n",
        "cls_dict[\"target\"] = targets_list\n",
        "\n",
        "print(\"Predicted target:\", cls_dict[\"target\"][y_cls_pred[\"target\"]])\n",
        "\n",
        "for k in cls_dict:\n",
        "    if k != \"target\":\n",
        "        print(f\"{k}: {cls_dict[k][y_cls_pred[k]]}\")\n",
        "\n",
        "# print level for each emotion\n",
        "for i in range(y_emo_pred.shape[1]):\n",
        "    k = emotions[i]\n",
        "    print(f\"{k}: {value_to_level(y_emo_pred[:,i], quantiles[k])}\")\n",
        "\n",
        "# print level for each mid-level feature\n",
        "for i in range(y_mid_pred.shape[1]):\n",
        "    k = mid_levels[i]\n",
        "    print(f\"{k}: {value_to_level(y_mid_pred[:,i], quantiles[k])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1y-eSbzK1rI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
