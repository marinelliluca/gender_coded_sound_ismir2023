{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinelliluca/gender_coded_sound_ismir2023/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fD6kv8bhJsyP"
      },
      "source": [
        "### GENDER-CODED SOUND: Analysing the Gendering of Music in Toy Commercials via Multi-Task Learning\n",
        "\n",
        "Demo from https://github.com/marinelliluca/gender_coded_sound_ismir2023\n",
        "\n",
        "#### Usage: \n",
        "- from the menu, select Runtime > Run all\n",
        "- you can change the input video by providing a youtube link to a toy commercial below\n",
        "\n",
        "#### Disclaimer\n",
        "The loaded model supports only two target audiences (masculine or feminine), and is therefore not generalizable to mixed audience commercials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKQIINen-GX2"
      },
      "outputs": [],
      "source": [
        "!pip install yt-dlp\n",
        "!pip install pytorch_lightning\n",
        "!pip install librosa\n",
        "!pip install torchopenl3\n",
        "!pip install ffmpeg moviepy\n",
        "!git clone https://github.com/marinelliluca/gender_coded_sound_ismir2023.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA0tx_x3_3RM",
        "outputId": "d4f654ea-33cf-4803-bcc0-42257f2dd548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gender_coded_sound_ismir2023\n"
          ]
        }
      ],
      "source": [
        "%cd gender_coded_sound_ismir2023/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6uAHytC7g-x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from utils import DynamicMultitasker, embedding_dimensions\n",
        "from compute_embeddings import compute_openl3\n",
        "\n",
        "import yt_dlp\n",
        "import moviepy.editor as mp\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import yaml, json\n",
        "from IPython.display import YouTubeVideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SwiMNC7ZMMD_"
      },
      "outputs": [],
      "source": [
        "which = \"openl3_env\"\n",
        "voice = True\n",
        "targets_list = [\"Girls/women\", \"Boys/men\"]\n",
        "\n",
        "with open(\"config_save.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# load quantile normalization parameters\n",
        "with open(f\"quantiles_{which}_voice_{voice}_{len(targets_list)}_cls.json\", \"r\") as f:\n",
        "    quantiles = json.load(f)\n",
        "\n",
        "\n",
        "# scales quantization\n",
        "def value_to_level(value, quantiles):\n",
        "    # quantiles = [0.33, 0.67]\n",
        "    if value <= quantiles[0]:\n",
        "        return \"low\"\n",
        "    elif value <= quantiles[1]:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"high\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=iW7yZlEaPA4\n",
            "[youtube] iW7yZlEaPA4: Downloading webpage\n",
            "[youtube] iW7yZlEaPA4: Downloading ios player API JSON\n",
            "[youtube] iW7yZlEaPA4: Downloading android player API JSON\n",
            "[youtube] iW7yZlEaPA4: Downloading m3u8 information\n",
            "[info] iW7yZlEaPA4: Downloading 1 format(s): 22\n",
            "[download] Destination: ./iW7yZlEaPA4.mp4\n",
            "[download] 100% of    3.04MiB in 00:00:00 at 7.70MiB/s   \n"
          ]
        }
      ],
      "source": [
        "#@title Download YouTube video (insert URL)\n",
        "youtube_url = \"https://www.youtube.com/watch?v=iW7yZlEaPA4\" #@param {type:\"string\"}\n",
        "\n",
        "yt_id = youtube_url.split(\"watch?v=\")[-1]\n",
        "\n",
        "video_path = f'./{yt_id}.mp4'\n",
        "\n",
        "ydl_opts = {\n",
        "    'outtmpl': video_path,\n",
        "    \"format\": \"mp4\",\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([youtube_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "YouTubeVideo(yt_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Extract audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Writing audio in ./iW7yZlEaPA4.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "video = mp.VideoFileClip(video_path)\n",
        "\n",
        "# trim 5 last seconds (which usually contain the audio logo of the retailer)\n",
        "# video = video.subclip(0, video.duration - 5)\n",
        "\n",
        "video.audio.write_audiofile(video_path.replace(\"mp4\",\"mp3\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5x5u3gN7xDB"
      },
      "source": [
        "### load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moc8wHr77v0Z",
        "outputId": "c1299d9c-f5eb-4e9b-ecdb-500fe6a143e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DynamicMultitasker(\n",
              "  (hidden): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (hidden_mid): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (out_mid): Linear(in_features=128, out_features=12, bias=True)\n",
              "  (hidden_emo): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (out_emo): Linear(in_features=128, out_features=6, bias=True)\n",
              "  (bn_cls): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (hidden_cls): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (out_cls): ModuleDict(\n",
              "    (voice_gender): Linear(in_features=128, out_features=4, bias=True)\n",
              "    (voice_exagg): Linear(in_features=128, out_features=4, bias=True)\n",
              "    (voice_type): Linear(in_features=128, out_features=4, bias=True)\n",
              "    (voice_age): Linear(in_features=128, out_features=4, bias=True)\n",
              "    (target): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set the parameters for the model\n",
        "config[\"cls_dict\"][\"target\"] = targets_list # add target list to config\n",
        "params = {\n",
        "    \"input_dim\": embedding_dimensions[\"music\"][which],\n",
        "    \"n_emo\": 6,\n",
        "    \"n_mid\": 12,\n",
        "    \"cls_dict\": config[\"cls_dict\"],\n",
        "    \"filmed\": False,\n",
        "}\n",
        "\n",
        "# Load model:\n",
        "model = DynamicMultitasker(**params)\n",
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "    f\"models/{which}_{voice}_voice_{len(targets_list)}_cls.pt\"\n",
        "    )\n",
        ")\n",
        "model.eval()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b3sRDRLGKsPn"
      },
      "source": [
        "## Compute OpenL3 (env) embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBOpjdTiId3b",
        "outputId": "6eeb660d-e98a-4e42-b9dc-7ed344dbba12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/torchopenl3/torchopenl3-models/raw/master/torchopenl3_mel128_env_512.pth.tar\" to /root/.cache/torch/hub/checkpoints/torchopenl3_mel128_env_512.pth.tar\n",
            "100%|██████████| 34.4M/34.4M [00:00<00:00, 172MB/s]\n"
          ]
        }
      ],
      "source": [
        "embedding = compute_openl3(video_path.replace(\"mp4\",\"mp3\")).mean(axis=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8KRGfBwBLWmn"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V7HNKlYXLvC3"
      },
      "outputs": [],
      "source": [
        "emotions = ['Happy', 'Beauty', 'Calm', 'Energizing', 'Angry', 'Triumphant']\n",
        "\n",
        "mid_levels = [\n",
        "       'Electric/Acoustic', 'Distorted/Clear', 'Many/Few Instruments',\n",
        "       'Loud/Soft', 'Heavy/Light', 'High/Low pitch', 'Punchy/Smooth',\n",
        "       'Harmonious/Disharmonious', 'Clear melody/No melody',\n",
        "       'Complex/Simple rhythm', 'Dense/Sparse', 'Strong beat/Weak beat'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bk5ydZyKoSv",
        "outputId": "3ec9d254-242c-4056-bd2b-e2ac08779c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted target: Boys/men\n",
            "voice_gender: Masculine\n",
            "voice_exagg: Yes a masculine voice is gender exaggerated\n",
            "voice_type: Spoken\n",
            "voice_age: Adults (including young adults)\n",
            "Happy: low\n",
            "Beauty: low\n",
            "Calm: low\n",
            "Energizing: high\n",
            "Angry: high\n",
            "Triumphant: high\n",
            "Electric/Acoustic: low\n",
            "Distorted/Clear: low\n",
            "Many/Few Instruments: medium\n",
            "Loud/Soft: medium\n",
            "Heavy/Light: low\n",
            "High/Low pitch: high\n",
            "Punchy/Smooth: medium\n",
            "Harmonious/Disharmonious: high\n",
            "Clear melody/No melody: high\n",
            "Complex/Simple rhythm: medium\n",
            "Dense/Sparse: low\n",
            "Strong beat/Weak beat: high\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    y_mid_pred, y_emo_pred, y_cls_pred = model(\n",
        "        torch.from_numpy(embedding[np.newaxis,:]).float()\n",
        "    )\n",
        "\n",
        "y_emo_pred = y_emo_pred.numpy()\n",
        "y_mid_pred = y_mid_pred.numpy()\n",
        "y_cls_pred = {k: int(torch.argmax(y_cls_pred[k], dim=1).numpy()) for k in config[\"cls_dict\"]}\n",
        "\n",
        "cls_dict = config[\"cls_dict\"]\n",
        "cls_dict[\"target\"] = targets_list\n",
        "\n",
        "print(\"Predicted target:\", cls_dict[\"target\"][y_cls_pred[\"target\"]])\n",
        "\n",
        "for k in cls_dict:\n",
        "    if k != \"target\":\n",
        "        print(f\"{k}: {cls_dict[k][y_cls_pred[k]]}\")\n",
        "\n",
        "# print level for each emotion\n",
        "for i in range(y_emo_pred.shape[1]):\n",
        "    k = emotions[i]\n",
        "    print(f\"{k}: {value_to_level(y_emo_pred[:,i], quantiles[k])}\")\n",
        "\n",
        "# print level for each mid-level feature\n",
        "for i in range(y_mid_pred.shape[1]):\n",
        "    k = mid_levels[i]\n",
        "    print(f\"{k}: {value_to_level(y_mid_pred[:,i], quantiles[k])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S1y-eSbzK1rI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNfPT4ERNLjiuAhE60eTCnE",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
