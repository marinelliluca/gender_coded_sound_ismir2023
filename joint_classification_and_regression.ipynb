{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import MultipleRegressionWithSoftmax, EmbeddingsDataset\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "modality = 'music' # 'music', 'speech', or 'video'\n",
    "which = 'openl3' # 'mfcc', 'msd' or 'openl3' for music, 'slow_fast' for video, 'hubert' for speech\n",
    "voice = False \n",
    "drop_non_significant = True\n",
    "\n",
    "fn_suffix = {\n",
    "    'music': {\n",
    "        'mfcc': '',\n",
    "        'msd': '_backend', \n",
    "        'openl3': '_music', # '_music' or '_env'\n",
    "    },\n",
    "    'video': {\n",
    "        'slow_fast': '_slow', # '_slow' or '_fast'\n",
    "    },\n",
    "    'speech': {\n",
    "        'hubert': '_wave_encoder', # '_wave_encoder' or '_transformer'\n",
    "    }\n",
    "}\n",
    "\n",
    "embedding_dimensions = {\n",
    "    'video': {\n",
    "        'slow_fast': 2048 if fn_suffix['video']['slow_fast']=='_slow' else 256,\n",
    "    },\n",
    "    'music': {\n",
    "        'mfcc': 60,\n",
    "        'msd': 256,\n",
    "        'openl3': 512,\n",
    "    },\n",
    "    'speech': {\n",
    "        'hubert': 1024 if fn_suffix['speech']['hubert']=='_transformer' else 512,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_df = pd.read_csv(\"groundtruth_merged.csv\")\n",
    "groundtruth_df.set_index(\"stimulus_id\", inplace=True)\n",
    "groundtruth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_and_mid_level = pd.read_csv(\"emotions_and_mid_level.csv\")\n",
    "emotions_and_mid_level.set_index(\"stimulus_id\", inplace=True)\n",
    "\n",
    "if drop_non_significant:\n",
    "    # drop columns that are not significant based on the ANOVA test\n",
    "    to_drop = [\"Amusing\", \"Many/Few Instruments\", \"Wide/Narrow pitch variation\", \n",
    "               \"Repetitive/Non-repetitive\", \"Complex/Simple rhythm\", \"Fast tempo/Slow tempo\"] \n",
    "    emotions_and_mid_level = emotions_and_mid_level.drop(columns=to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "emotions_and_mid_level.boxplot(ax=ax, rot=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = 0\n",
    "for stimulus_id in groundtruth_df.index:\n",
    "    if not os.path.exists(f\"{modality}/embeddings_{which}/{stimulus_id}{fn_suffix[modality][which]}.npy\"):\n",
    "        print(f\"Embedding for {stimulus_id} not found\")\n",
    "        not_found += 1\n",
    "\n",
    "assert not_found == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = embedding_dimensions[modality][which]\n",
    "\n",
    "X = np.empty((groundtruth_df.shape[0], embedding_dim))\n",
    "y_reg = np.empty((emotions_and_mid_level.shape[0], emotions_and_mid_level.shape[1]))\n",
    "\n",
    "for i,stimulus_id in enumerate(groundtruth_df.index):\n",
    "    embedding = np.load(f\"{modality}/embeddings_{which}{'' if voice else '_novoice'}/\" +\n",
    "                        f\"{stimulus_id}{fn_suffix[modality][which]}.npy\")\n",
    "    X[i] = embedding.mean(axis=0)\n",
    "    y_reg[i] = emotions_and_mid_level.loc[stimulus_id].values\n",
    "\n",
    "X.shape, y_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Girls/women\", \"Boys/men\"] if n_classes==2 else [\"Girls/women\", \"Mixed\", \"Boys/men\"]\n",
    "\n",
    "y_cls = groundtruth_df.target.values\n",
    "\n",
    "# convert to integers, and when the classes are not in 'classes' set them to -1\n",
    "y_cls = groundtruth_df.target.values\n",
    "y_cls = [classes.index(x) if x in classes else -1 for x in y_cls]\n",
    "y_cls = np.array(y_cls)\n",
    "\n",
    "pd.Series(y_cls).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partially annotated data will be handeled by the model, see utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_dim\": X.shape[1], \n",
    "    \"n_regressions\": y_reg.shape[1], \n",
    "    \"output_dim\": n_classes,\n",
    "    }\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "f1s = []\n",
    "r2s = []\n",
    "pearsons = []\n",
    "ps = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    test_index, val_index = train_test_split(test_index, test_size=0.5, random_state=42)\n",
    "    \n",
    "    X_train, X_test, X_val = X[train_index], X[test_index], X[val_index]\n",
    "    y_reg_train, y_reg_test, y_reg_val = y_reg[train_index], y_reg[test_index], y_reg[val_index]\n",
    "    y_cls_train, y_cls_test, y_cls_val = y_cls[train_index], y_cls[test_index], y_cls[val_index]\n",
    "\n",
    "    train_dataset = EmbeddingsDataset(X_train, y_reg_train, y_cls_train)\n",
    "    val_dataset = EmbeddingsDataset(X_val, y_reg_val, y_cls_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=1)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=1)\n",
    " \n",
    "    model = MultipleRegressionWithSoftmax(**params)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "    trainer = pl.Trainer(max_epochs=100,\n",
    "                         callbacks=[checkpoint_callback, EarlyStopping(monitor='val_loss', patience=30)],\n",
    "                         enable_progress_bar = False,\n",
    "                         accelerator='gpu',\n",
    "                         devices=1)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # load best model\n",
    "    model = model.load_from_checkpoint(checkpoint_callback.best_model_path, **params)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_reg_pred, out_cls = model(torch.from_numpy(X_test).float())\n",
    "    \n",
    "    skip_unlabelled = y_cls_test != -1\n",
    "    y_cls_pred = torch.argmax(out_cls, dim=1).numpy()[skip_unlabelled]\n",
    "    y_cls_test = y_cls_test[skip_unlabelled]\n",
    "\n",
    "    accuracies.append(accuracy_score(y_cls_test, y_cls_pred))\n",
    "    f1s.append(f1_score(y_cls_test, y_cls_pred, average='weighted'))\n",
    "\n",
    "    r2_values = r2_score(y_reg_test, y_reg_pred, multioutput='raw_values')\n",
    "    r2s.append(r2_values)\n",
    "\n",
    "    r = [pearsonr(y_reg_test[:,i], y_reg_pred[:,i])[0] for i in range(y_reg_test.shape[1])]\n",
    "    p = [pearsonr(y_reg_test[:,i], y_reg_pred[:,i])[1] for i in range(y_reg_test.shape[1])]\n",
    "    pearsons.append(r)\n",
    "    ps.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Accuracy: {np.mean(accuracies):.2f} ± {np.std(accuracies):.2f}\")\n",
    "print(f\"F1: {np.mean(f1s):.2f} ± {np.std(f1s):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose to get r2s per feature\n",
    "r2s = np.array(r2s).T\n",
    "\n",
    "for i, r2 in enumerate(r2s):\n",
    "    print(f\"R2 for {emotions_and_mid_level.columns[i]}: {np.mean(r2):.2f} ± {np.std(r2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: compute standard deviation by row, and then average over all rows\n",
    "print(f\"Average R2 for all responses: {np.mean(r2s):.2f} ± {np.mean(np.std(r2s, axis=1)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose to get pearsons per feature\n",
    "pearsons = np.array(pearsons).T\n",
    "ps = np.array(ps).T\n",
    "\n",
    "p2star = lambda p: ''.join(['*' for alpha in [0.001,0.01,0.05] if p<=alpha/len(ps[0])]) # Bonferroni correction\n",
    "\n",
    "for i, r in enumerate(pearsons):\n",
    "    print(f\"Pearson's r for {emotions_and_mid_level.columns[i]}: {np.mean(r):.2f} ± {np.std(r):.2f} , significances {[p2star(p) for p in ps[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Pearson's r for all responses: {np.mean(pearsons):.2f} ± {np.mean(np.std(pearsons, axis=1)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how the last trained model performs on the unlabeled data of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_commercials = groundtruth_df.index[test_index]\n",
    "no_actors_commercials = groundtruth_df[groundtruth_df.target == \"There are no actors/presenters or you can never see their faces\"].index\n",
    "unseen_no_actors_commercials = no_actors_commercials.intersection(test_commercials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stimulus_id in unseen_no_actors_commercials:\n",
    "        # retrieve embedding\n",
    "        embedding = np.load(f\"{modality}/embeddings_{which}{'' if voice else '_novoice'}/\" +\n",
    "                            f\"{stimulus_id}{fn_suffix[modality][which]}.npy\")\n",
    "        \n",
    "        # predict\n",
    "        with torch.no_grad():\n",
    "            y_reg_pred, out_cls = model(torch.from_numpy(embedding.mean(axis=0)).float())\n",
    "\n",
    "        y_cls_pred = torch.argmax(out_cls).numpy()\n",
    "\n",
    "        # print results\n",
    "        print(f\"https://www.youtube.com/watch?v={stimulus_id} - predicted {classes[y_cls_pred]}\")\n",
    "\n",
    "        print(\"Regression:\")\n",
    "        for i, feature in enumerate(emotions_and_mid_level.columns):\n",
    "            print(f\"\\t{feature}: predicted {y_reg_pred[i]:.2f}, actual {emotions_and_mid_level.loc[stimulus_id, feature]:.2f}\")\n",
    "        \n",
    "        # # write to text file all the results\n",
    "        # with open(f\"results_{modality}_{which}.txt\", \"a\") as f:\n",
    "        #     f.write(f\"https://www.youtube.com/watch?v={stimulus_id} - predicted {classes[y_cls_pred]}\\n\")\n",
    "        #     f.write(\"Regression:\\n\")\n",
    "        #     for i, feature in enumerate(emotions_and_mid_level.columns):\n",
    "        #         f.write(f\"\\t{feature}: predicted {y_reg_pred[i]:.2f}, actual {emotions_and_mid_level.loc[stimulus_id, feature]:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings_pipeline_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
