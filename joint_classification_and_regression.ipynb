{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import MultipleRegressionWithSoftmax, EmbeddingsDataset2\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "modality = 'music' # 'music', 'speech', or 'video'\n",
    "which = 'openl3' # 'mfcc', 'msd' or 'openl3' for music, 'slow_fast' for video, 'hubert' for speech\n",
    "voice = True \n",
    "\n",
    "fn_suffix = {\n",
    "    'music': {\n",
    "        'mfcc': '',\n",
    "        'msd': '_backend', \n",
    "        'openl3': '_music', # '_music' or '_env'\n",
    "    },\n",
    "    'video': {\n",
    "        'slow_fast': '_slow', # '_slow' or '_fast'\n",
    "    },\n",
    "    'speech': {\n",
    "        'hubert': '_wave_encoder', # '_wave_encoder' or '_transformer'\n",
    "    }\n",
    "}\n",
    "\n",
    "embedding_dimensions = {\n",
    "    'video': {\n",
    "        'slow_fast': 2048 if fn_suffix['video']['slow_fast']=='_slow' else 256,\n",
    "    },\n",
    "    'music': {\n",
    "        'mfcc': 60,\n",
    "        'msd': 256,\n",
    "        'openl3': 512,\n",
    "    },\n",
    "    'speech': {\n",
    "        'hubert': 1024 if fn_suffix['speech']['hubert']=='_transformer' else 512,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_df = pd.read_csv(\"groundtruth_merged.csv\")\n",
    "groundtruth_df.set_index(\"stimulus_id\", inplace=True)\n",
    "groundtruth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_level_features = pd.read_csv(\"mid_level_features.csv\").drop(columns=[\"target\"])\n",
    "mid_level_features.set_index(\"stimulus_id\", inplace=True)\n",
    "\n",
    "# drop columns that are not significant based on the ANOVA test in the music cognition paper\n",
    "todrop = [\"Wide pitch variation/Narrow pitch variation\", \"Repetitive/Non-repetitive\", \"Fast tempo/Slow tempo\"]\n",
    "mid_level_features = mid_level_features.drop(columns=todrop)\n",
    "\n",
    "# perform min-max scaling [0, 1] of all mid-level features\n",
    "mid_level_features = (mid_level_features - mid_level_features.min()) / (mid_level_features.max() - mid_level_features.min())\n",
    "mid_level_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = 0\n",
    "for stimulus_id in groundtruth_df.index:\n",
    "    if not os.path.exists(f\"{modality}/embeddings_{which}/{stimulus_id}{fn_suffix[modality][which]}.npy\"):\n",
    "        print(f\"Embedding for {stimulus_id} not found\")\n",
    "        not_found += 1\n",
    "\n",
    "assert not_found == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = embedding_dimensions[modality][which]\n",
    "\n",
    "X = np.empty((groundtruth_df.shape[0], embedding_dim))\n",
    "y_reg = np.empty((mid_level_features.shape[0], mid_level_features.shape[1]))\n",
    "\n",
    "for i,stimulus_id in enumerate(groundtruth_df.index):\n",
    "    embedding = np.load(f\"{modality}/embeddings_{which}{'' if voice else '_novoice'}/\" +\n",
    "                        f\"{stimulus_id}{fn_suffix[modality][which]}.npy\")\n",
    "    X[i] = embedding.mean(axis=0)\n",
    "    y_reg[i] = mid_level_features.loc[stimulus_id].values\n",
    "\n",
    "X.shape, y_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Girls/women\", \"Boys/men\"] if n_classes==2 else [\"Girls/women\", \"Mixed\", \"Boys/men\"]\n",
    "# mask = groundtruth_df.target.isin(classes) \n",
    "\n",
    "y_cls = groundtruth_df.target.values\n",
    "\n",
    "# convert to integers, and when the classes are not in 'classes' set them to -1\n",
    "y_cls = groundtruth_df.target.values\n",
    "y_cls = [classes.index(x) if x in classes else -1 for x in y_cls]\n",
    "y_cls = np.array(y_cls)\n",
    "\n",
    "pd.Series(y_cls).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partially annotated data will be handeled by the model, see utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_dim\": X.shape[1], \n",
    "    \"n_regressions\": y_reg.shape[1], \n",
    "    \"output_dim\": n_classes\n",
    "    }\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "f1s = []\n",
    "r2s = []\n",
    "pearsons = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    test_index, val_index = train_test_split(test_index, test_size=0.5, random_state=42)\n",
    "    \n",
    "    X_train, X_test, X_val = X[train_index], X[test_index], X[val_index]\n",
    "    y_reg_train, y_reg_test, y_reg_val = y_reg[train_index], y_reg[test_index], y_reg[val_index]\n",
    "    y_cls_train, y_cls_test, y_cls_val = y_cls[train_index], y_cls[test_index], y_cls[val_index]\n",
    "\n",
    "    train_dataset = EmbeddingsDataset2(X_train, y_reg_train, y_cls_train)\n",
    "    val_dataset = EmbeddingsDataset2(X_val, y_reg_val, y_cls_val)\n",
    "    test_dataset = EmbeddingsDataset2(X_test, y_reg_test, y_cls_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=1)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1)\n",
    "\n",
    "    model = MultipleRegressionWithSoftmax(**params)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "    trainer = pl.Trainer(max_epochs=200,\n",
    "                        callbacks=[checkpoint_callback, EarlyStopping(monitor='val_loss', patience=50)],\n",
    "                        enable_progress_bar = False,\n",
    "                        accelerator='gpu',\n",
    "                        devices=1)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "    # load best model\n",
    "    model = model.load_from_checkpoint(checkpoint_callback.best_model_path, **params)\n",
    "    \n",
    "    # evaluate\n",
    "    skip_unlabelled = y_cls_test != -1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_reg_pred, out_cls = model(torch.from_numpy(X_test).float())\n",
    "    \n",
    "    y_cls_pred = torch.argmax(out_cls, dim=1).numpy()[skip_unlabelled]\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_cls_test[skip_unlabelled], y_cls_pred))\n",
    "    f1s.append(f1_score(y_cls_test[skip_unlabelled], y_cls_pred, average='weighted'))\n",
    "\n",
    "    r2_values = r2_score(y_reg_test, y_reg_pred, multioutput='raw_values')\n",
    "    r2s.append(r2_values)\n",
    "\n",
    "    r = [pearsonr(y_reg_test[:,i], y_reg_pred[:,i])[0] for i in range(y_reg_test.shape[1])]\n",
    "    pearsons.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {np.mean(accuracies):.2f} ± {np.std(accuracies):.2f}\")\n",
    "print(f\"F1: {np.mean(f1s):.2f} ± {np.std(f1s):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose to get r2s per feature\n",
    "r2s = np.array(r2s).T\n",
    "\n",
    "for i, r2 in enumerate(r2s):\n",
    "    print(f\"R2 for {mid_level_features.columns[i]}: {np.mean(r2):.2f} ± {np.std(r2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose to get pearsons per feature\n",
    "pearsons = np.array(pearsons).T\n",
    "#\n",
    "for i, r in enumerate(pearsons):\n",
    "    print(f\"Pearson's r for {mid_level_features.columns[i]}: {np.mean(r):.2f} ± {np.std(r):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings_pipeline_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
